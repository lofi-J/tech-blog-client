// ëª¨ë“ˆ ì„ ì–¸
pub mod https;
pub mod types;

use std::fs;
use std::fs::read_dir;
use std::path::{Path, PathBuf};

use crate::types::{Metadata, PostMetadata, SearchIndex, SearchIndexMetadata};

use sha2::{Digest, Sha256};

// ì»¨í…ì¸  ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ ê²½ë¡œ ë°˜í™˜
fn get_content_file_paths(dir_path: &str) -> Vec<PathBuf> {
    let content_directory = Path::new(dir_path).to_path_buf();
    let read_dir = read_dir(content_directory).unwrap();

    read_dir
        .filter_map(|entry| entry.ok())
        .map(|entry| entry.path())
        .collect()
}

// Stringì„ ë°›ì•„ metadataë§Œ ì¶”ì¶œ
fn extract_metadata(content: String) -> Option<String> {
    if !content.starts_with("---") {
        return None;
    }

    let lines: Vec<&str> = content.lines().collect();
    let mut metadata = String::new();
    let mut in_frontmatter = false;

    for line in lines {
        if line.trim() == "---" {
            if !in_frontmatter {
                in_frontmatter = true;
                continue;
            } else {
                break;
            }
        }

        if in_frontmatter {
            metadata.push_str(line);
            metadata.push('\n');
        }
    }

    if !metadata.is_empty() {
        Some(metadata.trim().to_string())
    } else {
        None
    }
}

// ë³€í™˜í•œ hashê°’ ë°˜í™˜
fn get_hash_as_u64(text: &String) -> u64 {
    let mut hasher = Sha256::new();
    hasher.update(text.as_bytes());
    let result = hasher.finalize();

    let hex_string = format!("{:x}", result);
    // ì²˜ìŒ 16ìë¦¬ hexë¥¼ u64ë¡œ íŒŒì‹±
    u64::from_str_radix(&hex_string[..16], 16).unwrap()
}

// ë©”íƒ€ë°ì´í„°ì—ì„œ íŠ¹ì • í‚¤ì˜ ê°’ë§Œ ì¶”ì¶œ
fn extract_metadata_value(yaml_str: &str, key: &str) -> Option<String> {
    let metadata = parse_yaml_metadata(yaml_str).expect("YAML PASING ERROR");

    match key {
        "title" => Some(metadata.title),
        "thumbnail" => Some(metadata.thumbnail),
        "slug" => Some(metadata.slug),
        "description" => Some(metadata.description),
        "category" => Some(metadata.category),
        "tags" => Some(metadata.tags.join(", ")),
        "published" => Some(metadata.published),
        _ => panic!("{:?} is not a valid metadata", key),
    }
}

// YAML ë©”íƒ€ë°ì´í„°ë¥¼ Metadata êµ¬ì¡°ì²´ë¡œ íŒŒì‹±
fn parse_yaml_metadata(yaml_str: &str) -> Result<Metadata, serde_yaml::Error> {
    serde_yaml::from_str(yaml_str)
}

// ëª¨ë“  MDX íŒŒì¼ì„ íŒŒì‹±í•´ PostMetadata êµ¬ì¡°ì²´ ìƒì„±
fn generate_all_posts_metadata(file_paths: Vec<PathBuf>) -> Vec<PostMetadata> {
    let mut vec_post_metadata = Vec::<PostMetadata>::new();

    for file_path in &file_paths {
        let file_name = file_path // slugë¡œ ì‚¬ìš©
            .file_name()
            .unwrap()
            .to_str()
            .unwrap()
            .replace(".mdx", "");

        let content = fs::read_to_string(file_path).unwrap();
        let metadata_str = if let Some(metadata) = extract_metadata(content.clone()) {
            metadata
        } else {
            panic!(
                "Error file: '{}' due to missing or invalid frontmatter.",
                file_name
            );
        };

        let generated_hash_code = get_hash_as_u64(&content);

        // ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
        let title = extract_metadata_value(&metadata_str, "title").unwrap();
        let thumbnail = extract_metadata_value(&metadata_str, "thumbnail").unwrap();
        let slug = extract_metadata_value(&metadata_str, "slug").unwrap();
        let description = extract_metadata_value(&metadata_str, "description").unwrap();
        let category = extract_metadata_value(&metadata_str, "category").unwrap();
        let published = extract_metadata_value(&metadata_str, "published").unwrap();
        let tags = extract_metadata_value(&metadata_str, "tags").unwrap();

        // ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í›„ íŒŒì¼ëª…ê³¼ slug ë§¤ì¹­ í™•ì¸
        if slug != file_name {
            panic!("Slug and File name mismatch: {} != {}", slug, file_name);
        }

        let post_metadata = PostMetadata {
            title,
            thumbnail,
            slug,
            description,
            category,
            published,
            tags: tags
                .split(", ")
                .map(|s| s.to_string())
                .collect::<Vec<String>>(),
            hash_code: generated_hash_code,
        };

        // ì „ì²´ postë¦¬ìŠ¤íŠ¸ì— ì‚½ì…
        vec_post_metadata.push(post_metadata);
    }

    vec_post_metadata
}

// main ì—ì„œ ì‹¤í–‰í•  í•¨ìˆ˜
pub async fn execute_mdx_sync() {
    let vec_file_paths = get_content_file_paths("src/content");
    let local_post_metadata = generate_all_posts_metadata(vec_file_paths); // ëª¨ë“  íŒŒì¼ íŒŒì‹± í›„ ë©”íƒ€ë°ì´í„° ë²¡í„° ìƒì„±

    let mut success_count = 0;
    let mut error_count = 0;

    for post_metadata in local_post_metadata {
        match https::upsert_post_metadata(post_metadata.clone()).await {
            Ok(_response) => {
                success_count += 1;
            }
            Err(e) => {
                error_count += 1;
                println!("âŒ Failed to upsert '{}': {}", post_metadata.slug, e);
            }
        }
    }

    // ìµœì¢… ê²°ê³¼ ì¶œë ¥
    println!("âœ… Success: {} posts", success_count);
    println!("âŒ Errors: {} posts", error_count);
    println!("ğŸ“Š Total: {} posts", success_count + error_count);
}

pub fn execute_mdx_indexing() {
    let emit_json_path = "public/search-index/index.json";
    let vec_file_paths = get_content_file_paths("src/content");

    let parent = Path::new(emit_json_path).parent().unwrap();
    fs::create_dir_all(parent).unwrap();

    let mut search_indices = Vec::<SearchIndex>::new();

    for file_path in &vec_file_paths {
        let file_name = file_path
            .file_name()
            .unwrap()
            .to_str()
            .unwrap()
            .replace(".mdx", "");

        let content = fs::read_to_string(file_path).unwrap();
        let only_article_content = content
            .split("---")
            .nth(2)
            .unwrap()
            .to_string()
            .replace("\n", "");

        let metadata_str = extract_metadata(content.clone()).unwrap();

        let title = extract_metadata_value(&metadata_str, "title").unwrap();
        let description = extract_metadata_value(&metadata_str, "description").unwrap();
        let published = extract_metadata_value(&metadata_str, "published").unwrap_or_default();
        let category = extract_metadata_value(&metadata_str, "category").unwrap_or_default();
        let tags = extract_metadata_value(&metadata_str, "tags")
            .unwrap()
            .split(", ")
            .map(|s| s.to_string())
            .collect::<Vec<String>>();

        let search_index = SearchIndex {
            metadata: SearchIndexMetadata {
                title,
                slug: file_name.clone(),
                description,
                category,
                published,
                tags,
            },
            content: only_article_content,
        };

        search_indices.push(search_index);
        println!("âœ… Indexed: {}", file_name);
    }

    // JSON íŒŒì¼ë¡œ ì €ì¥
    let json_string = serde_json::to_string_pretty(&search_indices).unwrap();
    fs::write(emit_json_path, json_string).unwrap();

    println!("ğŸ“„ Search index saved to: {}", emit_json_path);
    println!("ğŸ“Š Total indexed posts: {}", search_indices.len());
}
